{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from preprocess_interviews import get_token_labels\n",
    "import torch\n",
    "from RobertaForMultiTokenClassification import RobertaForMultiLabelTokenClassification\n",
    "\n",
    "import os\n",
    "# os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# if torch.has_mps:\n",
    "#     device = torch.device('mps')\n",
    "\n",
    "model_checkpoint = \"./robbert-v2-dutch-base-finetuned-sentiment/checkpoint-12032\"\n",
    "roberta_model = RobertaForMultiLabelTokenClassification.from_pretrained(model_checkpoint)\n",
    "roberta_model.to(device)\n",
    "\n",
    "data, unique_labels = get_token_labels(code_mode=\"sentiment\", stride=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "splitter = GroupShuffleSplit(test_size=.10, n_splits=2, random_state=7)\n",
    "split = splitter.split(df, groups=df['transcript_name'])\n",
    "train_ids, test_ids = next(split)\n",
    "\n",
    "train = df.iloc[train_ids]\n",
    "test = df.iloc[test_ids]\n",
    "\n",
    "test['transcript_name']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, multilabel_confusion_matrix\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "import torch\n",
    "import os\n",
    "\n",
    "%env PYTORCH_ENABLE_MPS_FALLBACK=1\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = \"1\"\n",
    "print(os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"])\n",
    "\n",
    "# Initialize variables\n",
    "true_labels, pred_labels = [], []\n",
    "transcript_accuracies = []  # Initialize empty list to hold accuracy values\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in trange(len(test)):\n",
    "        piece = test.iloc[i]\n",
    "        input_ids = torch.IntTensor(piece['input_ids']).unsqueeze(0).to(device)\n",
    "        attention_mask = torch.IntTensor(piece['attention_mask']).unsqueeze(0).to(device)\n",
    "\n",
    "        output: TokenClassifierOutput = roberta_model(input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        pred_label = output.logits.to('cpu').squeeze(0).numpy()\n",
    "        true_label = np.array(piece['labels'])\n",
    "        \n",
    "        pred_labels.append(pred_label)\n",
    "        true_labels.append(true_label)\n",
    "        \n",
    "        # Flatten the lists\n",
    "        flat_pred_label = pred_label.ravel()\n",
    "        flat_true_label = true_label.ravel()\n",
    "        \n",
    "        # Calculate the accuracy for this iteration and append to list\n",
    "        iter_accuracy = accuracy_score(flat_pred_label > 0.50, flat_true_label)\n",
    "        transcript_accuracies.append(iter_accuracy)\n",
    "\n",
    "# Calculate the average, standard deviation, and range of accuracies\n",
    "avg_accuracy = np.mean(transcript_accuracies) * 100\n",
    "std_accuracy = np.std(transcript_accuracies) * 100\n",
    "min_accuracy = np.min(transcript_accuracies) * 100\n",
    "max_accuracy = np.max(transcript_accuracies) * 100\n",
    "\n",
    "# Output the overall statistics with one decimal place\n",
    "print(f\"Average Accuracy: {avg_accuracy:.1f}%\")\n",
    "print(f\"Standard Deviation of Accuracy: {std_accuracy:.1f}%\")\n",
    "print(f\"Range of Accuracy: {min_accuracy:.1f}% - {max_accuracy:.1f}%\")\n",
    "\n",
    "# Continue with your existing code to calculate final accuracy and confusion matrices\n",
    "threshold = 0.50\n",
    "pred_labels = [[el > threshold for el in p] for true, pred in zip(true_labels, pred_labels) for t, p in zip(true, pred) if t[0] > -50]\n",
    "true_labels = [item for sublist in true_labels for item in sublist if item[0] > -50]\n",
    "\n",
    "cm_multi = multilabel_confusion_matrix(true_labels, pred_labels)\n",
    "accuracy_value = accuracy_score(pred_labels, true_labels)\n",
    "\n",
    "print(accuracy_value)\n",
    "\n",
    "for i in range(0, len(unique_labels)):\n",
    "    cm_multi[i] = np.fliplr(np.rot90(cm_multi[i]))\n",
    "\n",
    "print(cm_multi)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(cm_multi)\n",
    "cm_multi_ration = np.array(cm_multi, dtype=float)\n",
    "\n",
    "for idx in range(len(cm_multi)):\n",
    "    cm_multi_ration[idx] = cm_multi[idx] * 100 / np.sum(cm_multi[idx])\n",
    "\n",
    "cm_multi_ration = np.round_(cm_multi_ration, decimals=1)\n",
    "\n",
    "cm_multi_ration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "fig, axs = plt.subplots(2,2)\n",
    "fig.set_size_inches(12, 15)\n",
    "\n",
    "def calc_accuracy(i):\n",
    "    true_1 = cm_multi[i,0,0] + cm_multi[i,1,1]\n",
    "    false_1 = cm_multi[i,1,0] + cm_multi[i,0,1]\n",
    "    return true_1 / (true_1 + false_1)\n",
    "\n",
    "def calc_sensitivity(i):\n",
    "    tp = cm_multi[i,1,1]\n",
    "    fn = cm_multi[i,1,0]\n",
    "    return round(tp / (tp + fn), 2)\n",
    "\n",
    "def calc_specificity(i):\n",
    "    tn = cm_multi[i,0,0]\n",
    "    fp = cm_multi[i,0,1]\n",
    "    return round(tn / (tn + fp), 2)\n",
    "\n",
    "tick_labels = ['Present', 'Absent']\n",
    "xlabel = \"Text mining\"\n",
    "ylabel = \"Manual\"\n",
    "axes_font_size = 30\n",
    "label_font_size = 20\n",
    "tick_label_size = 15\n",
    "result_size = 25\n",
    "\n",
    "\n",
    "display(unique_labels)\n",
    "\n",
    "colormap = ListedColormap(['white'])\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "b = sns.heatmap(cm_multi_ration[0], annot=cm_multi_ration[0], fmt='', cmap=colormap, annot_kws={\"size\": result_size}, cbar=False,\n",
    "                linewidths=1, linecolor='black')\n",
    "b.set_xticklabels(tick_labels, size = tick_label_size)\n",
    "b.set_yticklabels(tick_labels, size = tick_label_size)\n",
    "axs[0, 0].set_title('Context', fontsize=axes_font_size, fontweight='bold')\n",
    "plt.xlabel(xlabel, fontsize=label_font_size, fontweight='bold')\n",
    "plt.ylabel(ylabel, fontsize=label_font_size, fontweight='bold')\n",
    "b.xaxis.tick_top()\n",
    "b.xaxis.set_label_position('top')\n",
    "\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "b = sns.heatmap(cm_multi_ration[1], annot=cm_multi_ration[1], fmt='', cmap=colormap, annot_kws={\"size\": result_size}, cbar=False,\n",
    "                linewidths=1, linecolor='black')\n",
    "b.set_xticklabels(tick_labels, size = tick_label_size)\n",
    "b.set_yticklabels(tick_labels, size = tick_label_size)\n",
    "axs[0, 1].set_title('Expectations', fontsize=axes_font_size, fontweight='bold')\n",
    "plt.xlabel(xlabel, fontsize=label_font_size, fontweight='bold')\n",
    "plt.ylabel(ylabel, fontsize=label_font_size, fontweight='bold')\n",
    "b.xaxis.tick_top()\n",
    "b.xaxis.set_label_position('top')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "b = sns.heatmap(cm_multi_ration[2], annot=cm_multi_ration[2], fmt='', cmap=colormap, annot_kws={\"size\": result_size}, cbar=False,\n",
    "                linewidths=1, linecolor='black')\n",
    "b.set_xticklabels(tick_labels, size = tick_label_size)\n",
    "b.set_yticklabels(tick_labels, size = tick_label_size)\n",
    "axs[1, 0].set_title('Experienced QoC', fontsize=axes_font_size, fontweight='bold')\n",
    "plt.xlabel(xlabel, fontsize=label_font_size, fontweight='bold')\n",
    "plt.ylabel(ylabel, fontsize=label_font_size, fontweight='bold')\n",
    "b.xaxis.tick_top()\n",
    "b.xaxis.set_label_position('top')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "b = sns.heatmap(cm_multi_ration[3], annot=cm_multi_ration[3], fmt='', cmap=colormap, annot_kws={\"size\": result_size}, cbar=False,\n",
    "                linewidths=1, linecolor='black')\n",
    "b.set_xticklabels(tick_labels, size = tick_label_size)\n",
    "b.set_yticklabels(tick_labels, size = tick_label_size)\n",
    "axs[1, 1].set_title('Experiences', fontsize=axes_font_size, fontweight='bold')\n",
    "plt.xlabel(xlabel, fontsize=label_font_size, fontweight='bold')\n",
    "plt.ylabel(ylabel, fontsize=label_font_size, fontweight='bold')\n",
    "b.xaxis.tick_top()\n",
    "b.xaxis.set_label_position('top')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
